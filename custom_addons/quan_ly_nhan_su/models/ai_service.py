# -*- coding: utf-8 -*-
"""
AI Service - Google Gemini 2.5 Integration v·ªõi Auto API Rotation
T√≠ch h·ª£p 5 API keys, t·ª± ƒë·ªông chuy·ªÉn key khi h·∫øt quota
"""

import logging
import google.genai as genai
from odoo import api, models, _
from odoo.exceptions import UserError
import os
import json

_logger = logging.getLogger(__name__)


class AIService(models.AbstractModel):
    """Service t√≠ch h·ª£p Google Gemini AI v·ªõi 5 API keys rotation"""
    
    _name = 'ai.service'
    _description = 'AI Service for Gemini Integration with Auto Rotation'

    # Fallback API Keys - Ph√¢n b·ªï theo ch·ª©c nƒÉng
    DEFAULT_API_KEYS = [
        "AIzaSyApIoPs91hDIor3pA3PjlNPoVV0nzPeMl0",  # Key #1: Document Analysis & Employee Eval
        "AIzaSyAEKaLFrnUbHQ8jbGu23jk5hGop2UJMQbw",  # Key #2: Customer Scoring & Backup
        "AIzaSyAb5Fxtzg0AlFrWv4I6SKE34hr10v8OY-Y",  # Key #3: Work Report Comparison (CRITICAL)
        "AIzaSyAZ887ml8jI01uAwnuN7DCduczUg9zsyDM",  # Key #4: Quality Assessment
        "AIzaSyBEALAyUVpOGbsFKkM2SX5LdR2n4QWOhcg"   # Key #5: Recommendations & Advanced
    ]
    
    current_key_index = 0
    
    @api.model
    def _get_api_keys(self):
        """
        L·∫•y API keys t·ª´ config parameter ho·∫∑c fallback v·ªÅ default
        Format trong config: key1,key2,key3,key4,key5
        """
        try:
            config_param = self.env['ir.config_parameter'].sudo().get_param(
                'quan_ly_nhan_su.gemini_api_keys', ''
            )
            if config_param:
                keys = [k.strip() for k in config_param.split(',') if k.strip()]
                if len(keys) >= 5:
                    _logger.info("‚úÖ Using API keys from config parameter")
                    return keys
        except Exception as e:
            _logger.warning(f"‚ö†Ô∏è Could not load API keys from config: {str(e)}")
        
        _logger.info("‚ö†Ô∏è Using default API keys (fallback)")
        return self.DEFAULT_API_KEYS
    
    # API Key assignment by function
    API_ASSIGNMENT = {
        'employee_eval': 0,        # Key #1
        'customer_scoring': 1,     # Key #2
        'report_comparison': 2,    # Key #3 (CRITICAL)
        'quality_assessment': 3,   # Key #4
        'recommendations': 4,      # Key #5
        'document_parsing': 0,     # Key #1 (shared)
        'task_assignment': 1,      # Key #2 (shared)
        'deadline_estimation': 2,  # Key #3 (shared)
        'progress_tracking': 3,    # Key #4 (shared)
        'communication_check': 4   # Key #5 (shared)
    }
    
    @api.model
    def _get_api_key_for_function(self, function_name):
        """
        L·∫•y API key theo ch·ª©c nƒÉng
        
        Args:
            function_name: T√™n ch·ª©c nƒÉng (employee_eval, customer_scoring, ...)
        
        Returns:
            tuple: (API key, key_index)
        """
        api_keys = self._get_api_keys()
        key_index = self.API_ASSIGNMENT.get(function_name, self.current_key_index)
        if key_index >= len(api_keys):
            key_index = 0
        key = api_keys[key_index]
        _logger.info(f"üîë Using API Key #{key_index + 1} for '{function_name}'")
        return key, key_index
    
    @api.model
    def _get_next_api_key(self):
        """L·∫•y API key ti·∫øp theo (rotation) - Fallback"""
        api_keys = self._get_api_keys()
        if self.current_key_index >= len(api_keys):
            self.current_key_index = 0
        key = api_keys[self.current_key_index]
        _logger.info(f"Using Gemini API key #{self.current_key_index + 1}/{len(api_keys)}")
        return key
    
    @api.model
    def _rotate_api_key(self):
        """Chuy·ªÉn sang API key ti·∫øp theo"""
        api_keys = self._get_api_keys()
        old_index = self.current_key_index
        self.current_key_index = (self.current_key_index + 1) % len(api_keys)
        _logger.warning(f"üîÑ API Rotation: Key #{old_index + 1} ‚Üí Key #{self.current_key_index + 1}")
        return self.current_key_index

    @api.model
    def _call_gemini_with_retry(self, prompt, max_retries=5, function_name='default'):
        """
        Call Gemini 2.5 API v·ªõi auto-retry v√† rotation khi h·∫øt quota
        S·ª≠ d·ª•ng Google GenAI SDK m·ªõi
        
        Args:
            prompt (str): Prompt g·ª≠i cho AI
            max_retries (int): S·ªë l·∫ßn retry (= s·ªë API keys)
            function_name (str): T√™n ch·ª©c nƒÉng ƒë·ªÉ ch·ªçn API key ph√π h·ª£p
        
        Returns:
            str: Response t·ª´ AI
        """
        for attempt in range(max_retries):
            try:
                # L·∫•y API key theo ch·ª©c nƒÉng
                api_key, key_index = self._get_api_key_for_function(function_name)
                
                # Kh·ªüi t·∫°o client v·ªõi API key
                try:
                    client = genai.Client(api_key=api_key)
                except Exception as e:
                    _logger.error(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o Gemini client: {str(e)}")
                    # Fallback: th·ª≠ v·ªõi key ti·∫øp theo
                    if attempt < max_retries - 1:
                        self._rotate_api_key()
                        continue
                    raise
                
                # G·ªçi API v·ªõi model gemini-2.5-flash
                try:
                    response = client.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=prompt
                    )
                except Exception as e:
                    error_msg = str(e).lower()
                    if any(x in error_msg for x in ['quota', 'resource_exhausted', '429', 'rate limit', 'permission']):
                        _logger.warning(f"‚ö†Ô∏è API Key #{key_index + 1} quota/permission error")
                        if attempt < max_retries - 1:
                            self._rotate_api_key()
                            continue
                    raise
                
                if response and hasattr(response, 'text') and response.text:
                    _logger.info(f"‚úÖ Gemini 2.5 API success (attempt {attempt + 1}, key #{key_index + 1})")
                    return response.text
                elif response and hasattr(response, 'candidates') and response.candidates:
                    # Fallback: l·∫•y text t·ª´ candidates
                    text = response.candidates[0].content.parts[0].text if response.candidates[0].content.parts else ""
                    if text:
                        _logger.info(f"‚úÖ Gemini 2.5 API success (from candidates)")
                        return text
                    else:
                        raise Exception("Empty response from Gemini")
                else:
                    raise Exception("Empty response from Gemini")
                    
            except Exception as e:
                error_msg = str(e).lower()
                
                # Check quota errors
                if any(x in error_msg for x in ['quota', 'resource_exhausted', '429', 'rate limit', 'permission']):
                    _logger.warning(f"‚ö†Ô∏è API Key #{key_index + 1} quota/permission exceeded")
                    self._rotate_api_key()
                    
                    if attempt < max_retries - 1:
                        _logger.info(f"üîÑ Retrying with next API key...")
                        continue
                
                # Other errors
                _logger.error(f"‚ùå Gemini API error (attempt {attempt + 1}): {str(e)[:200]}")
                
                if attempt < max_retries - 1:
                    self._rotate_api_key()
                    continue
                else:
                    # All keys failed - return fallback instead of raising
                    _logger.error(f"‚ùå T·∫•t c·∫£ {max_retries} API keys ƒë·ªÅu th·∫•t b·∫°i")
                    return None  # Return None ƒë·ªÉ caller c√≥ th·ªÉ x·ª≠ l√Ω fallback
        
        return None  # Return None thay v√¨ raise ƒë·ªÉ c√≥ th·ªÉ fallback

    # ==================== EMPLOYEE PERFORMANCE ANALYSIS ====================
    
    @api.model
    def analyze_employee_performance(self, employee_data):
        """
        Ph√¢n t√≠ch hi·ªáu su·∫•t nh√¢n vi√™n b·∫±ng AI
        
        TI√äU CH√ç ƒê√ÅNH GI√Å (0-100 ƒëi·ªÉm):
        1. Task Completion Rate (30%): T·ª∑ l·ªá ho√†n th√†nh c√¥ng vi·ªác
        2. On-Time Delivery (25%): Giao vi·ªác ƒë√∫ng h·∫°n
        3. Work Quality (20%): Ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác
        4. Skill Match (15%): Ph√π h·ª£p k·ªπ nƒÉng v·ªõi c√¥ng vi·ªác
        5. Growth Trend (10%): Xu h∆∞·ªõng ph√°t tri·ªÉn
        
        Args:
            employee_data (dict): {
                'name': str,
                'job_position': str,
                'department': str,
                'total_tasks': int,
                'completed_tasks': int,
                'overdue_tasks': int,
                'task_completion_rate': float,
                'average_task_score': float
            }
        
        Returns:
            dict: {
                'overall_score': float (0-100),
                'performance_level': str,
                'strengths': str,
                'improvements': str,
                'recommendations': str,
                'analysis': str
            }
        """
        try:
            prompt = f"""
B·∫°n l√† chuy√™n gia ƒë√°nh gi√° hi·ªáu su·∫•t nh√¢n vi√™n. Ph√¢n t√≠ch d·ªØ li·ªáu sau:

**TH√îNG TIN NH√ÇN VI√äN:**
- H·ªç t√™n: {employee_data.get('name')}
- V·ªã tr√≠: {employee_data.get('job_position')}
- Ph√≤ng ban: {employee_data.get('department', 'Ch∆∞a x√°c ƒë·ªãnh')}

**TH·ªêNG K√ä C√îNG VI·ªÜC:**
- T·ªïng c√¥ng vi·ªác: {employee_data.get('total_tasks', 0)}
- Ho√†n th√†nh: {employee_data.get('completed_tasks', 0)}
- Qu√° h·∫°n: {employee_data.get('overdue_tasks', 0)}
- T·ª∑ l·ªá ho√†n th√†nh: {employee_data.get('task_completion_rate', 0):.1f}%
- ƒêi·ªÉm ch·∫•t l∆∞·ª£ng TB: {employee_data.get('average_task_score', 0):.1f}/100

**TI√äU CH√ç ƒê√ÅNH GI√Å:**
1. Task Completion Rate (30%): {employee_data.get('task_completion_rate', 0):.1f}%
2. On-Time Delivery (25%): {(employee_data.get('completed_tasks', 0) - employee_data.get('overdue_tasks', 0)) / max(employee_data.get('completed_tasks', 1), 1) * 100:.1f}%
3. Work Quality (20%): {employee_data.get('average_task_score', 0):.1f}/100
4. Skill Match (15%): ƒê√°nh gi√° theo v·ªã tr√≠
5. Growth Trend (10%): Xu h∆∞·ªõng c·∫£i thi·ªán

Tr·∫£ v·ªÅ JSON (KH√îNG markdown, ch·ªâ JSON thu·∫ßn):
{{
    "overall_score": <ƒëi·ªÉm 0-100>,
    "performance_level": "<poor/below_average/average/good/excellent/outstanding>",
    "strengths": "<3-5 ƒëi·ªÉm m·∫°nh, m·ªói ƒëi·ªÉm 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚úì>",
    "improvements": "<3-5 ƒëi·ªÉm c·∫£i thi·ªán, m·ªói ƒëi·ªÉm 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚ö†>",
    "recommendations": "<3-5 khuy·∫øn ngh·ªã, m·ªói khuy·∫øn ngh·ªã 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚Üí>",
    "analysis": "<ph√¢n t√≠ch ng·∫Øn g·ªçn 2-3 c√¢u>"
}}
"""
            
            response_text = self._call_gemini_with_retry(prompt, function_name='employee_eval')
            
            if not response_text:
                # Fallback n·∫øu AI kh√¥ng kh·∫£ d·ª•ng
                return self._fallback_employee_analysis(employee_data)
            
            # Parse JSON
            response_text = self._clean_json_response(response_text)
            try:
                result = json.loads(response_text)
            except json.JSONDecodeError as e:
                _logger.error(f"‚ùå JSON parse error: {str(e)}. Response: {response_text[:200]}")
                return self._fallback_employee_analysis(employee_data)
            
            # Validate & set defaults
            result.setdefault('overall_score', 70)
            result['overall_score'] = max(0, min(100, float(result['overall_score'])))
            
            _logger.info(f"‚úÖ Employee AI analysis: {employee_data.get('name')} = {result['overall_score']}/100")
            return result
            
        except Exception as e:
            _logger.error(f"‚ùå Employee analysis failed: {str(e)[:200]}")
            return self._fallback_employee_analysis(employee_data)
    
    @api.model
    def _fallback_employee_analysis(self, data):
        """Fallback khi AI kh√¥ng kh·∫£ d·ª•ng"""
        completion = data.get('task_completion_rate', 0)
        quality = data.get('average_task_score', 0)
        total_tasks = data.get('total_tasks', 0)
        overdue_tasks = data.get('overdue_tasks', 0)
        completed_tasks = data.get('completed_tasks', 0)
        
        ontime_rate = 100 if overdue_tasks == 0 and completed_tasks > 0 else max(0, 100 - (overdue_tasks / max(completed_tasks, 1)) * 100)
        
        # T√≠nh ƒëi·ªÉm chi ti·∫øt
        completion_score = completion * 0.3
        ontime_score = ontime_rate * 0.25
        quality_score = quality * 0.20
        workload_score = min(10, (total_tasks / 20) * 10) * 0.15
        growth_score = 70 * 0.10  # Default
        
        score = completion_score + ontime_score + quality_score + workload_score + growth_score
        
        return {
            'overall_score': round(score, 1),
            'performance_level': 'excellent' if score >= 85 else ('good' if score >= 75 else ('average' if score >= 60 else 'below_average')),
            'completion_score': round(completion_score, 1),
            'quality_score': round(quality_score, 1),
            'deadline_score': round(ontime_score, 1),
            'efficiency_score': round(workload_score, 1),
            'growth_score': round(growth_score, 1),
            'strengths': f"‚úì T·ª∑ l·ªá ho√†n th√†nh: {completion:.1f}%\n‚úì Ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác: {quality:.1f}/100\n‚úì T·ªïng c√¥ng vi·ªác: {total_tasks}",
            'improvements': "‚ö† C·∫£i thi·ªán t·ªëc ƒë·ªô" if ontime_rate < 80 else "‚ö† Duy tr√¨ hi·ªáu su·∫•t",
            'recommendations': "‚Üí Ti·∫øp t·ª•c ph√°t tri·ªÉn k·ªπ nƒÉng\n‚Üí TƒÉng nƒÉng su·∫•t l√†m vi·ªác\n‚Üí Gi·∫£m c√¥ng vi·ªác qu√° h·∫°n",
            'analysis': f"Nh√¢n vi√™n ho√†n th√†nh {completion:.1f}% c√¥ng vi·ªác v·ªõi ch·∫•t l∆∞·ª£ng {quality:.1f}/100. T·ªïng {total_tasks} c√¥ng vi·ªác, {overdue_tasks} qu√° h·∫°n."
        }
    
    @api.model
    def analyze_employee_performance_detailed(self, employee_data):
        """
        Ph√¢n t√≠ch hi·ªáu su·∫•t nh√¢n vi√™n chi ti·∫øt b·∫±ng AI (n√¢ng cao)
        
        Returns th√™m c√°c ƒëi·ªÉm s·ªë chi ti·∫øt cho bi·ªÉu ƒë·ªì
        """
        try:
            prompt = f"""
B·∫°n l√† chuy√™n gia ƒë√°nh gi√° hi·ªáu su·∫•t nh√¢n vi√™n. Ph√¢n t√≠ch CHI TI·∫æT d·ªØ li·ªáu sau:

**TH√îNG TIN NH√ÇN VI√äN:**
- H·ªç t√™n: {employee_data.get('name')}
- V·ªã tr√≠: {employee_data.get('job_position')}
- Ph√≤ng ban: {employee_data.get('department', 'Ch∆∞a x√°c ƒë·ªãnh')}
- S·ªë nƒÉm l√†m vi·ªác: {employee_data.get('working_years', 0)}

**TH·ªêNG K√ä C√îNG VI·ªÜC:**
- T·ªïng c√¥ng vi·ªác: {employee_data.get('total_tasks', 0)}
- Ho√†n th√†nh: {employee_data.get('completed_tasks', 0)}
- Qu√° h·∫°n: {employee_data.get('overdue_tasks', 0)}
- T·ª∑ l·ªá ho√†n th√†nh: {employee_data.get('task_completion_rate', 0):.1f}%
- ƒêi·ªÉm ch·∫•t l∆∞·ª£ng TB: {employee_data.get('average_task_score', 0):.1f}/100

**Y√äU C·∫¶U:**
Tr·∫£ v·ªÅ JSON (KH√îNG markdown, ch·ªâ JSON thu·∫ßn) v·ªõi c√°c tr∆∞·ªùng:
{{
    "overall_score": <ƒëi·ªÉm 0-100>,
    "performance_level": "<poor/below_average/average/good/excellent/outstanding>",
    "completion_score": <ƒëi·ªÉm 0-30>,
    "quality_score": <ƒëi·ªÉm 0-20>,
    "deadline_score": <ƒëi·ªÉm 0-25>,
    "efficiency_score": <ƒëi·ªÉm 0-15>,
    "growth_score": <ƒëi·ªÉm 0-10>,
    "strengths": "<3-5 ƒëi·ªÉm m·∫°nh, m·ªói ƒëi·ªÉm 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚úì>",
    "improvements": "<3-5 ƒëi·ªÉm c·∫£i thi·ªán, m·ªói ƒëi·ªÉm 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚ö†>",
    "recommendations": "<3-5 khuy·∫øn ngh·ªã, m·ªói khuy·∫øn ngh·ªã 1 d√≤ng, b·∫Øt ƒë·∫ßu ‚Üí>",
    "analysis": "<ph√¢n t√≠ch ng·∫Øn g·ªçn 2-3 c√¢u>"
}}
"""
            
            response_text = self._call_gemini_with_retry(prompt, function_name='employee_eval')
            
            if not response_text:
                return self._fallback_employee_analysis(employee_data)
            
            response_text = self._clean_json_response(response_text)
            try:
                result = json.loads(response_text)
            except json.JSONDecodeError as e:
                _logger.error(f"‚ùå JSON parse error: {str(e)}")
                return self._fallback_employee_analysis(employee_data)
            
            # Validate & set defaults
            result.setdefault('overall_score', 70)
            result['overall_score'] = max(0, min(100, float(result['overall_score'])))
            result.setdefault('completion_score', 0)
            result.setdefault('quality_score', 0)
            result.setdefault('deadline_score', 0)
            result.setdefault('efficiency_score', 0)
            result.setdefault('growth_score', 0)
            
            _logger.info(f"‚úÖ Employee detailed AI analysis: {employee_data.get('name')} = {result['overall_score']}/100")
            return result
            
        except Exception as e:
            _logger.error(f"‚ùå Employee detailed analysis failed: {str(e)[:200]}")
            return self._fallback_employee_analysis(employee_data)
    
    # ==================== CUSTOMER SCORING ====================
    
    @api.model
    def analyze_customer_potential(self, customer_data):
        """
        Ph√¢n t√≠ch ti·ªÅm nƒÉng kh√°ch h√†ng b·∫±ng AI
        
        TI√äU CH√ç ƒê√ÅNH GI√Å (0-100 ƒëi·ªÉm):
        1. Revenue Potential (30%): Ti·ªÅm nƒÉng doanh thu
        2. Engagement Level (25%): M·ª©c ƒë·ªô t∆∞∆°ng t√°c
        3. Payment History (20%): L·ªãch s·ª≠ thanh to√°n
        4. Growth Potential (15%): Ti·ªÅm nƒÉng ph√°t tri·ªÉn
        5. Strategic Fit (10%): Ph√π h·ª£p chi·∫øn l∆∞·ª£c
        
        Args:
            customer_data (dict): D·ªØ li·ªáu kh√°ch h√†ng
        
        Returns:
            dict: {
                'ai_score': float (0-100),
                'score_level': str,
                'churn_risk': float (0-100),
                'recommendations': str
            }
        """
        try:
            prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch kh√°ch h√†ng CRM. ƒê√°nh gi√° ti·ªÅm nƒÉng:

**TH√îNG TIN:**
- T√™n: {customer_data.get('name')}
- Lo·∫°i: {customer_data.get('customer_type')}
- Ng√†nh: {customer_data.get('industry', 'N/A')}
- Quy m√¥: {customer_data.get('company_size', 'N/A')}

**TR·∫†NG TH√ÅI:**
- Status: {customer_data.get('status')}
- Level: {customer_data.get('level')}
- Ngu·ªìn: {customer_data.get('source', 'N/A')}

**T∆Ø∆†NG T√ÅC:**
- T·ªïng c√¥ng vi·ªác: {customer_data.get('total_tasks', 0)}
- Ho√†n th√†nh: {customer_data.get('completed_tasks', 0)}
- Ng√†y li√™n h·ªá cu·ªëi: {customer_data.get('last_contact_date', 'Ch∆∞a c√≥')}

**T√ÄI CH√çNH:**
- Doanh thu k·ª≥ v·ªçng: {customer_data.get('expected_revenue', 0):,.0f} VNƒê
- X√°c su·∫•t: {customer_data.get('probability', 0)}%

**TI√äU CH√ç:**
1. Revenue Potential (30%): Ti·ªÅm nƒÉng doanh thu
2. Engagement (25%): T∆∞∆°ng t√°c, ph·∫£n h·ªìi
3. Payment History (20%): Uy t√≠n thanh to√°n
4. Growth (15%): Xu h∆∞·ªõng ph√°t tri·ªÉn
5. Strategic Fit (10%): Ph√π h·ª£p m·ª•c ti√™u

Tr·∫£ v·ªÅ JSON (KH√îNG markdown):
{{
    "ai_score": <0-100>,
    "score_level": "<very_low/low/medium/high/very_high>",
    "churn_risk": <0-100 nguy c∆° m·∫•t kh√°ch>,
    "recommendations": "<3-5 khuy·∫øn ngh·ªã, m·ªói d√≤ng b·∫Øt ƒë·∫ßu üéØ/‚ö†Ô∏è/üí∞>"
}}
"""
            
            response_text = self._call_gemini_with_retry(prompt)
            response_text = self._clean_json_response(response_text)
            result = json.loads(response_text)
            
            result.setdefault('ai_score', 70)
            result.setdefault('churn_risk', 30)
            result['ai_score'] = max(0, min(100, float(result['ai_score'])))
            result['churn_risk'] = max(0, min(100, float(result['churn_risk'])))
            
            _logger.info(f"‚úÖ Customer AI score: {customer_data.get('name')} = {result['ai_score']}/100")
            return result
            
        except Exception as e:
            _logger.error(f"‚ùå Customer analysis failed: {str(e)[:200]}")
            return self._fallback_customer_analysis(customer_data)
    
    @api.model
    def _fallback_customer_analysis(self, data):
        """Fallback customer scoring"""
        revenue_score = min(100, data.get('expected_revenue', 0) / 100000000 * 100)
        prob_score = data.get('probability', 50)
        
        score = (revenue_score * 0.3 + prob_score * 0.7)
        
        return {
            'ai_score': round(score, 1),
            'score_level': 'high' if score >= 70 else 'medium',
            'churn_risk': 30,
            'recommendations': f"üéØ TƒÉng c∆∞·ªùng chƒÉm s√≥c\nüí∞ Khai th√°c ti·ªÅm nƒÉng {data.get('expected_revenue', 0):,.0f} VNƒê"
        }
    
    # ==================== TASK QUALITY EVALUATION ====================
    
    @api.model
    def analyze_task_quality(self, task_data):
        """
        ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác
        
        TI√äU CH√ç (0-100 ƒëi·ªÉm):
        1. Deliverable Quality (30%): Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m
        2. Time Efficiency (25%): Hi·ªáu qu·∫£ th·ªùi gian
        3. Requirement Match (20%): ƒê√°p ·ª©ng y√™u c·∫ßu
        4. Communication (15%): Giao ti·∫øp, b√°o c√°o
        5. Innovation (10%): T√≠nh s√°ng t·∫°o
        
        Args:
            task_data (dict): D·ªØ li·ªáu c√¥ng vi·ªác
        
        Returns:
            dict: K·∫øt qu·∫£ ƒë√°nh gi√°
        """
        try:
            prompt = f"""
ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác:

**C√îNG VI·ªÜC:** {task_data.get('name')}

**Y√äU C·∫¶U:**
{task_data.get('requirement', 'N/A')[:300]}

**K·∫æT QU·∫¢:**
{task_data.get('deliverable', 'N/A')[:300]}

**TH·ªúI GIAN:**
- ∆Ø·ªõc t√≠nh: {task_data.get('estimated_hours', 0)}h
- Th·ª±c t·∫ø: {task_data.get('actual_hours', 0)}h
- Hi·ªáu su·∫•t: {task_data.get('actual_hours', 1) / max(task_data.get('estimated_hours', 1), 1) * 100:.0f}%

**DEADLINE:**
- K·∫ø ho·∫°ch: {task_data.get('deadline')}
- Ho√†n th√†nh: {task_data.get('completed_date', 'Ch∆∞a xong')}
- {'‚úì ƒê√∫ng h·∫°n' if not task_data.get('is_overdue') else '‚úó Tr·ªÖ h·∫°n'}

**TI√äU CH√ç:**
1. Deliverable Quality (30%)
2. Time Efficiency (25%)
3. Requirement Match (20%)
4. Communication (15%)
5. Innovation (10%)

Tr·∫£ v·ªÅ JSON (KH√îNG markdown):
{{
    "quality_score": <0-100>,
    "time_score": <0-100>,
    "requirement_score": <0-100>,
    "overall": <0-100>,
    "analysis": "<ph√¢n t√≠ch 2-3 c√¢u>",
    "suggestions": "<2-3 g·ª£i √Ω c·∫£i thi·ªán>"
}}
"""
            
            response_text = self._call_gemini_with_retry(prompt)
            response_text = self._clean_json_response(response_text)
            result = json.loads(response_text)
            
            result.setdefault('overall', 70)
            result['overall'] = max(0, min(100, float(result['overall'])))
            
            _logger.info(f"‚úÖ Task quality: {task_data.get('name')} = {result['overall']}/100")
            return result
            
        except Exception as e:
            _logger.error(f"‚ùå Task analysis failed: {str(e)[:200]}")
            return self._fallback_task_analysis(task_data)
    
    @api.model
    def _fallback_task_analysis(self, data):
        """Fallback task quality"""
        time_eff = min(100, data.get('estimated_hours', 1) / max(data.get('actual_hours', 1), 1) * 100)
        ontime_score = 100 if not data.get('is_overdue') else 60
        
        overall = (time_eff * 0.5 + ontime_score * 0.5)
        
        return {
            'quality_score': 80,
            'time_score': round(time_eff, 1),
            'requirement_score': 75,
            'overall': round(overall, 1),
            'analysis': 'C√¥ng vi·ªác ho√†n th√†nh' + (' ƒë√∫ng h·∫°n' if not data.get('is_overdue') else ' tr·ªÖ h·∫°n'),
            'suggestions': 'Ti·∫øp t·ª•c duy tr√¨ ch·∫•t l∆∞·ª£ng'
        }
    
    # ==================== HELPER METHODS ====================
    
    @api.model
    def _clean_json_response(self, text):
        """Lo·∫°i b·ªè markdown v√† format JSON response"""
        text = text.strip()
        
        # Remove markdown code blocks
        if text.startswith('```json'):
            text = text[7:]
        elif text.startswith('```'):
            text = text[3:]
        
        if text.endswith('```'):
            text = text[:-3]
        
        return text.strip()
