# -*- coding: utf-8 -*-
"""
AI Service Advanced - T√≠nh nƒÉng AI n√¢ng cao
ƒê·∫∑c bi·ªát: AI ƒë√°nh gi√° b√°o c√°o c√¥ng vi·ªác (Work Report Analysis)
"""

import logging
import google.genai as genai
from odoo import api, models, _
from odoo.exceptions import UserError
import base64
import io
import re

_logger = logging.getLogger(__name__)

# Try import PDF/DOCX parsers
try:
    import PyPDF2
    PDF_AVAILABLE = True
except:
    PDF_AVAILABLE = False
    _logger.warning("PyPDF2 not available - PDF parsing disabled")

try:
    import docx
    DOCX_AVAILABLE = True
except:
    DOCX_AVAILABLE = False
    _logger.warning("python-docx not available - DOCX parsing disabled")


class AIServiceAdvanced(models.AbstractModel):
    """AI Service Advanced - Work Report Analysis & More"""
    
    _inherit = 'ai.service'
    
    # ==================== WORK REPORT ANALYSIS ====================
    
    @api.model
    def analyze_work_report_comprehensive(self, task_data, report_files=None):
        """
        AI ƒë√°nh gi√° b√°o c√°o c√¥ng vi·ªác TO√ÄN DI·ªÜN
        
        Quy tr√¨nh 4 b∆∞·ªõc v·ªõi 4 API keys ri√™ng bi·ªát:
        1. Extract text t·ª´ file (API Key #1)
        2. So s√°nh y√™u c·∫ßu vs k·∫øt qu·∫£ (API Key #3 - CRITICAL)
        3. ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng (API Key #4)
        4. G·ª£i √Ω c·∫£i thi·ªán (API Key #5)
        
        Args:
            task_data (dict): {
                'name': str,
                'requirement': str (HTML),
                'acceptance_criteria': str,
                'result_note': str (HTML),
                'deliverable': str,
                'estimated_hours': float,
                'actual_hours': float,
                'deadline': date,
                'completed_date': datetime,
                'is_overdue': bool
            }
            report_files (list): List of binary file data
        
        Returns:
            dict: {
                'extracted_text': str,
                'completion_percentage': float,
                'completed_items': list,
                'incomplete_items': list,
                'quality_score': float,
                'quality_details': str,
                'recommendations': str,
                'overall_score': float
            }
        """
        
        try:
            _logger.info(f"üöÄ Starting comprehensive work report analysis for: {task_data.get('name')}")
            
            # Step 1: Extract text from files (if any) - API Key #1
            extracted_text = ""
            if report_files and len(report_files) > 0:
                extracted_text = self._extract_text_from_files(report_files)
            
            # Combine all text sources
            full_report_content = self._combine_report_content(
                task_data.get('result_note', ''),
                task_data.get('deliverable', ''),
                extracted_text
            )
            
            # Step 2: Requirement vs Result Comparison - API Key #3 (CRITICAL)
            comparison_result = self._compare_requirement_vs_result(
                requirement=task_data.get('requirement', ''),
                acceptance_criteria=task_data.get('acceptance_criteria', ''),
                result_content=full_report_content,
                api_key_function='report_comparison'
            )
            
            # Step 3: Quality Assessment - API Key #4
            quality_result = self._assess_work_quality_detailed(
                task_data=task_data,
                report_content=full_report_content,
                api_key_function='quality_assessment'
            )
            
            # Step 4: Generate Recommendations - API Key #5
            recommendations = self._generate_work_recommendations(
                comparison_result=comparison_result,
                quality_result=quality_result,
                task_data=task_data,
                api_key_function='recommendations'
            )
            
            # Calculate overall score
            overall_score = self._calculate_overall_score(
                comparison_result.get('completion_percentage', 0),
                quality_result.get('quality_score', 0),
                task_data
            )
            
            _logger.info(f"‚úÖ Analysis complete: Overall Score = {overall_score}/100")
            
            return {
                'extracted_text': extracted_text,
                'completion_percentage': comparison_result.get('completion_percentage', 0),
                'completed_items': comparison_result.get('completed_items', []),
                'incomplete_items': comparison_result.get('incomplete_items', []),
                'quality_score': quality_result.get('quality_score', 0),
                'quality_details': quality_result.get('details', ''),
                'professionalism_score': quality_result.get('professionalism', 0),
                'documentation_score': quality_result.get('documentation', 0),
                'recommendations': recommendations,
                'overall_score': overall_score,
                'analysis_summary': self._generate_analysis_summary(comparison_result, quality_result)
            }
            
        except Exception as e:
            _logger.error(f"‚ùå Work report analysis failed: {str(e)[:200]}")
            return self._fallback_work_report_analysis(task_data)
    
    @api.model
    def _extract_text_from_files(self, file_data_list):
        """
        Tr√≠ch xu·∫•t text t·ª´ PDF/Word/Docs
        S·ª≠ d·ª•ng API Key #1 cho document parsing
        """
        extracted_texts = []
        
        for file_data in file_data_list:
            try:
                # file_data should be dict with 'name' and 'datas'
                filename = file_data.get('name', '').lower()
                file_binary = base64.b64decode(file_data.get('datas', ''))
                
                if filename.endswith('.pdf') and PDF_AVAILABLE:
                    text = self._extract_from_pdf(file_binary)
                    extracted_texts.append(text)
                elif filename.endswith(('.docx', '.doc')) and DOCX_AVAILABLE:
                    text = self._extract_from_docx(file_binary)
                    extracted_texts.append(text)
                else:
                    _logger.warning(f"Unsupported file type or parser not available: {filename}")
            except Exception as e:
                _logger.error(f"Error extracting text from file: {str(e)[:100]}")
        
        return "\n\n".join(extracted_texts)
    
    @api.model
    def _extract_from_pdf(self, file_binary):
        """Extract text from PDF"""
        try:
            pdf_file = io.BytesIO(file_binary)
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            
            return text.strip()
        except Exception as e:
            _logger.error(f"PDF extraction error: {e}")
            return ""
    
    @api.model
    def _extract_from_docx(self, file_binary):
        """Extract text from DOCX"""
        try:
            docx_file = io.BytesIO(file_binary)
            doc = docx.Document(docx_file)
            
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            return text.strip()
        except Exception as e:
            _logger.error(f"DOCX extraction error: {e}")
            return ""
    
    @api.model
    def _combine_report_content(self, result_note, deliverable, extracted_text):
        """K·∫øt h·ª£p t·∫•t c·∫£ n·ªôi dung b√°o c√°o"""
        # Remove HTML tags
        result_note_clean = re.sub(r'<[^>]+>', '', result_note or '')
        
        combined = []
        if result_note_clean:
            combined.append("=== K·∫æT QU·∫¢ TH·ª∞C T·∫æ ===\n" + result_note_clean)
        if deliverable:
            combined.append("=== S·∫¢N PH·∫®M B√ÄNGIAO ===\n" + deliverable)
        if extracted_text:
            combined.append("=== N·ªòI DUNG T·ª™ FILE B√ÅO C√ÅO ===\n" + extracted_text)
        
        return "\n\n".join(combined)
    
    @api.model
    def _compare_requirement_vs_result(self, requirement, acceptance_criteria, result_content, api_key_function):
        """
        So s√°nh y√™u c·∫ßu vs k·∫øt qu·∫£ - CRITICAL FUNCTION
        S·ª≠ d·ª•ng API Key #3 (dedicated)
        """
        try:
            # Get dedicated API key
            api_key, key_index = self._get_api_key_for_function(api_key_function)
            genai.configure(api_key=api_key)
            
            # Clean HTML
            requirement_clean = re.sub(r'<[^>]+>', '', requirement or '')
            criteria_clean = acceptance_criteria or 'Kh√¥ng c√≥ ti√™u ch√≠ c·ª• th·ªÉ'
            
            prompt = f"""
B·∫°n l√† chuy√™n gia ƒë√°nh gi√° c√¥ng vi·ªác. So s√°nh Y√äU C·∫¶U vs K·∫æT QU·∫¢:

**Y√äU C·∫¶U BAN ƒê·∫¶U:**
{requirement_clean}

**TI√äU CH√ç NGHI·ªÜM THU:**
{criteria_clean}

**K·∫æT QU·∫¢ ƒê√É L√ÄM:**
{result_content}

H√ÉY PH√ÇN T√çCH:
1. Li·ªát k√™ t·ª´ng y√™u c·∫ßu: ƒê√É HO√ÄN TH√ÄNH / CH∆ØA HO√ÄN TH√ÄNH
2. T√≠nh % ho√†n th√†nh t·ªïng th·ªÉ
3. ƒê√°nh gi√° m·ª©c ƒë·ªô ƒë√°p ·ª©ng

Tr·∫£ v·ªÅ JSON (KH√îNG markdown):
{{
    "completion_percentage": <0-100>,
    "completed_items": ["Y√™u c·∫ßu 1 - ƒê√£ l√†m", "Y√™u c·∫ßu 2 - ƒê√£ l√†m", ...],
    "incomplete_items": ["Y√™u c·∫ßu X - Ch∆∞a l√†m", "Y√™u c·∫ßu Y - L√†m ch∆∞a ƒë·ªß", ...],
    "match_score": <0-100>,
    "summary": "<T√≥m t·∫Øt ng·∫Øn g·ªçn>"
}}
"""
            
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            
            if response and response.text:
                import json
                result_text = self._clean_json_response(response.text)
                result = json.loads(result_text)
                
                _logger.info(f"‚úÖ Requirement comparison: {result.get('completion_percentage')}% complete")
                return result
            
        except Exception as e:
            _logger.error(f"Requirement comparison error: {str(e)[:200]}")
        
        # Fallback
        return {
            'completion_percentage': 75,
            'completed_items': ['Ph·∫ßn l·ªõn y√™u c·∫ßu ƒë√£ ho√†n th√†nh'],
            'incomplete_items': ['M·ªôt s·ªë chi ti·∫øt c√≤n thi·∫øu'],
            'match_score': 75,
            'summary': 'ƒê√°nh gi√° t·ª± ƒë·ªông (fallback)'
        }
    
    @api.model
    def _assess_work_quality_detailed(self, task_data, report_content, api_key_function):
        """
        ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng chi ti·∫øt
        S·ª≠ d·ª•ng API Key #4
        """
        try:
            api_key, key_index = self._get_api_key_for_function(api_key_function)
            genai.configure(api_key=api_key)
            
            prompt = f"""
ƒê√°nh gi√° CH·∫§T L∆Ø·ª¢NG c√¥ng vi·ªác:

**C√îNG VI·ªÜC:** {task_data.get('name')}
**TH·ªúI GIAN:**
- ∆Ø·ªõc t√≠nh: {task_data.get('estimated_hours')}h
- Th·ª±c t·∫ø: {task_data.get('actual_hours')}h
- Deadline: {task_data.get('deadline')}
- Ho√†n th√†nh: {task_data.get('completed_date')}
- {'‚úì ƒê√∫ng h·∫°n' if not task_data.get('is_overdue') else '‚úó Tr·ªÖ h·∫°n'}

**B√ÅO C√ÅO:**
{report_content[:1500]}

ƒê√ÅNH GI√Å THEO 4 TI√äU CH√ç:
1. Quality (Ch·∫•t l∆∞·ª£ng): 0-100
2. Professionalism (Chuy√™n nghi·ªáp): 0-100
3. Completeness (ƒê·∫ßy ƒë·ªß): 0-100
4. Documentation (T√†i li·ªáu h√≥a): 0-100

Tr·∫£ v·ªÅ JSON:
{{
    "quality_score": <trung b√¨nh 4 ti√™u ch√≠>,
    "professionalism": <0-100>,
    "completeness": <0-100>,
    "documentation": <0-100>,
    "details": "<Ph√¢n t√≠ch chi ti·∫øt 3-4 c√¢u>",
    "strengths": ["ƒêi·ªÉm m·∫°nh 1", "ƒêi·ªÉm m·∫°nh 2"],
    "weaknesses": ["ƒêi·ªÉm y·∫øu 1", "ƒêi·ªÉm y·∫øu 2"]
}}
"""
            
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            
            if response and response.text:
                import json
                result_text = self._clean_json_response(response.text)
                result = json.loads(result_text)
                
                _logger.info(f"‚úÖ Quality assessment: {result.get('quality_score')}/100")
                return result
            
        except Exception as e:
            _logger.error(f"Quality assessment error: {str(e)[:200]}")
        
        # Fallback
        time_score = min(100, task_data.get('estimated_hours', 1) / max(task_data.get('actual_hours', 1), 1) * 100)
        ontime_score = 100 if not task_data.get('is_overdue') else 70
        
        return {
            'quality_score': (time_score + ontime_score) / 2,
            'professionalism': 80,
            'completeness': 75,
            'documentation': 70,
            'details': 'C√¥ng vi·ªác ho√†n th√†nh v·ªõi ch·∫•t l∆∞·ª£ng ·ªïn ƒë·ªãnh.',
            'strengths': ['Ho√†n th√†nh c√¥ng vi·ªác'],
            'weaknesses': ['C·∫ßn c·∫£i thi·ªán documentation']
        }
    
    @api.model
    def _generate_work_recommendations(self, comparison_result, quality_result, task_data, api_key_function):
        """
        T·∫°o g·ª£i √Ω c·∫£i thi·ªán
        S·ª≠ d·ª•ng API Key #5
        """
        try:
            api_key, key_index = self._get_api_key_for_function(api_key_function)
            genai.configure(api_key=api_key)
            
            prompt = f"""
D·ª±a tr√™n k·∫øt qu·∫£ ƒë√°nh gi√°:

**HO√ÄN TH√ÄNH:** {comparison_result.get('completion_percentage')}%
**CH·∫§T L∆Ø·ª¢NG:** {quality_result.get('quality_score')}/100
**ƒêI·ªÇM M·∫†NH:** {', '.join(quality_result.get('strengths', []))}
**ƒêI·ªÇM Y·∫æU:** {', '.join(quality_result.get('weaknesses', []))}

H√ÉY ƒê∆ØA RA:
1. 3-5 g·ª£i √Ω C·∫¢I THI·ªÜN c·ª• th·ªÉ
2. Training/Learning suggestions
3. Process improvements

Tr·∫£ v·ªÅ HTML format (kh√¥ng JSON):
<ul>
<li><strong>‚Üí</strong> G·ª£i √Ω 1...</li>
<li><strong>‚Üí</strong> G·ª£i √Ω 2...</li>
...
</ul>
"""
            
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            
            if response and response.text:
                _logger.info(f"‚úÖ Recommendations generated")
                return response.text.strip()
            
        except Exception as e:
            _logger.error(f"Recommendations generation error: {str(e)[:200]}")
        
        # Fallback
        return """
<ul>
<li><strong>‚Üí</strong> Ti·∫øp t·ª•c duy tr√¨ ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác</li>
<li><strong>‚Üí</strong> C·∫£i thi·ªán documentation v√† reporting</li>
<li><strong>‚Üí</strong> T·ªëi ∆∞u h√≥a quy tr√¨nh l√†m vi·ªác</li>
</ul>
"""
    
    @api.model
    def _calculate_overall_score(self, completion_pct, quality_score, task_data):
        """T√≠nh ƒëi·ªÉm t·ªïng th·ªÉ"""
        # Completion: 40%
        # Quality: 30%
        # On-time: 20%
        # Efficiency: 10%
        
        ontime_score = 100 if not task_data.get('is_overdue') else 60
        
        estimated = task_data.get('estimated_hours', 1)
        actual = task_data.get('actual_hours', 1)
        efficiency = min(100, (estimated / max(actual, 1)) * 100)
        
        overall = (
            completion_pct * 0.40 +
            quality_score * 0.30 +
            ontime_score * 0.20 +
            efficiency * 0.10
        )
        
        return round(overall, 1)
    
    @api.model
    def _generate_analysis_summary(self, comparison, quality):
        """T·∫°o t√≥m t·∫Øt ph√¢n t√≠ch"""
        summary = f"""
**üìä T√ìM T·∫ÆT PH√ÇN T√çCH:**

‚Ä¢ Ho√†n th√†nh: {comparison.get('completion_percentage')}%
‚Ä¢ Ch·∫•t l∆∞·ª£ng: {quality.get('quality_score')}/100
‚Ä¢ Chuy√™n nghi·ªáp: {quality.get('professionalism')}/100
‚Ä¢ Documentation: {quality.get('documentation')}/100

{comparison.get('summary', '')}
"""
        return summary.strip()
    
    @api.model
    def _fallback_work_report_analysis(self, task_data):
        """Fallback khi AI kh√¥ng kh·∫£ d·ª•ng"""
        estimated = task_data.get('estimated_hours', 1)
        actual = task_data.get('actual_hours', 1)
        
        time_score = min(100, (estimated / max(actual, 1)) * 100)
        ontime_score = 100 if not task_data.get('is_overdue') else 70
        
        overall = (time_score + ontime_score) / 2
        
        return {
            'extracted_text': '',
            'completion_percentage': 80,
            'completed_items': ['C√¥ng vi·ªác ƒë√£ ho√†n th√†nh'],
            'incomplete_items': [],
            'quality_score': overall,
            'quality_details': 'ƒê√°nh gi√° t·ª± ƒë·ªông (fallback mode)',
            'professionalism_score': 80,
            'documentation_score': 75,
            'recommendations': '<ul><li>Ti·∫øp t·ª•c duy tr√¨ ch·∫•t l∆∞·ª£ng</li></ul>',
            'overall_score': overall,
            'analysis_summary': 'C√¥ng vi·ªác ho√†n th√†nh v·ªõi ch·∫•t l∆∞·ª£ng t·ªët.'
        }
